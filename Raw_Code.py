# -*- coding: utf-8 -*-
"""B.cancerDetectionProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k2HKf3tuqJC6Yzj_qo6NSDR7GGUYXzJ4
"""

## Breast Cancer Detection

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

# reading data set and converting them to data frame df
df = pd.read_csv("data.csv")

# pringitn data set using head function and it will guve 5 row only , if want moew pass the integer inside head function
df.head()

df.info()   # provides summary of data set

df.isna().sum() # returns all the column with null value cnt

df.shape  # returns the no of rows and column

df = df.dropna(axis=1)

df.shape

df.describe()

df['diagnosis'].value_counts()

sns.countplot(df['diagnosis'] , label = "count")

# label encoding(convert the value of M and B into 1 and 0)
from sklearn.preprocessing import LabelEncoder
labelencoder_Y = LabelEncoder()
df.iloc[:,1]=labelencoder_Y.fit_transform(df.iloc[:,1].values)

df.head()

sns.pairplot(df.iloc[:,1:5], hue ="diagnosis")

df.iloc[:,1:32].corr()

plt.figure(figsize=(10,10))

sns.heatmap(df.iloc[:,1:5].corr() , annot=True ,fmt="0%")

# split the data set in to x and y , x = all row and col except output
X = df.iloc[:,2:31].values
Y = df.iloc[:,1].values

print(X)

#splitted the data set in to 80percent training and 20 percent testing rom sklearn.model_selection import train_test_split
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2 , random_state=0)

from sklearn.preprocessing import StandardScaler
X_train =  StandardScaler().fit_transform(X_train)
X_test =  StandardScaler().fit_transform(X_test)

def models(X_train,Y_train):
        #logistic regression
        from sklearn.linear_model import LogisticRegression
        log=LogisticRegression(random_state=0)
        log.fit(X_train,Y_train)
                                                    #LEAVE THIS

        #Decision Tree
        from sklearn.tree import DecisionTreeClassifier
        tree=DecisionTreeClassifier(random_state=0,criterion="entropy")
        tree.fit(X_train,Y_train)

        #Random Forest
        from sklearn.ensemble import RandomForestClassifier
        forest=RandomForestClassifier(random_state=0,criterion="entropy",n_estimators=10)
        forest.fit(X_train,Y_train)

        print('[0]logistic regression accuracy:',log.score(X_train,Y_train))
        print('[1]Decision tree accuracy:',tree.score(X_train,Y_train))
        print('[2]Random forest accuracy:',forest.score(X_train,Y_train))

        return log, tree,forest

# def models(X_train, Y_train):
#   #logistic regression
#   from sklearn.linear_model import LogisticRegression
#   from sklearn.preprocessing import LabelEncoder # Import LabelEncoder

#   log= LogisticRegression(random_state=0)

#   # Encode the labels in Y_train
#   le = LabelEncoder()
#   Y_train = le.fit_transform(Y_train) # Transform labels to numerical values

#   log.fit(X_train, Y_train)


#   #decision tree
#   from sklearn.tree import DecisionTreeClassifier
#   tree= DecisionTreeClassifier(random_state=0, criterion="entropy")
#   tree.fit(X_train, Y_train)


#   #random forest
#   from sklearn.ensemble import RandomForestClassifier
#   forest= RandomForestClassifier(random_state=0, criterion="entropy",n_estimators=10)
#   forest.fit(X_train, Y_train)

#   print('[0]Logistic Regression accuracy', log.score(X_train, Y_train))
#   print('[1]Decision Tree accuracy', tree.score(X_train, Y_train))
#   print('[2]Random Forest accuracy', forest.score(X_train, Y_train))



#   return log,tree,forest

# model= models(X_train, Y_train)

def eshi(X_train, Y_train):
    # Import necessary libraries
    from sklearn.linear_model import LogisticRegression
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.preprocessing import LabelEncoder

    # Initialize models
    log = LogisticRegression(random_state=0)
    tree = DecisionTreeClassifier(random_state=0, criterion="entropy")
    forest = RandomForestClassifier(random_state=0, criterion="entropy", n_estimators=10)

    # Encode the labels in Y_train
    le = LabelEncoder()
    Y_train_encoded = le.fit_transform(Y_train)

    # Fit the models
    log.fit(X_train, Y_train_encoded)
    tree.fit(X_train, Y_train_encoded)
    forest.fit(X_train, Y_train_encoded)

    # Print training accuracy
    print('[0] Logistic Regression accuracy', log.score(X_train, Y_train_encoded))
    print('[1] Decision Tree accuracy', tree.score(X_train, Y_train_encoded))
    print('[2] Random Forest accuracy', forest.score(X_train, Y_train_encoded))

    return log, tree, forest, le

# Train the models
log, tree, forest, le = eshi(X_train, Y_train)

# Encode the Y_test labels
Y_test_encoded = le.transform(Y_test)

# Import necessary metrics
from sklearn.metrics import accuracy_score, classification_report

# Evaluate the models
models = [log, tree, forest]
for i, model in enumerate(models):
    print("Model", i)
    predictions = model.predict(X_test)
    print(classification_report(Y_test_encoded, predictions))
    print('Accuracy : ', accuracy_score(Y_test_encoded, predictions))

#prediction of random forest...........1.0.0.?
pred= model[2].predict(X_test)
print('Predicted val')
print(pred)
print('actual val')
print(Y_test)

from joblib import dump
dump(model[2],"Cancer_prediction_model.joblib")